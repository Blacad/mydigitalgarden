---
{"dg-publish":true,"permalink":"/my-c-nnotes/lecture/lecture-4/","dgPassFrontmatter":true}
---


# 1 概述和传输层服务
---
- 传输层的位置
- 在TCP/IP网络中，这扇“门”称为套接字（socket），是应用层和传输层的接口，也是应用程序和网络之间的API
- 网络层 与 传输层
	- 网络层尽最大努力在终端间交付分组，但不提供任何承诺，具体来说，不保证交付，不保证按序交付，不保证数据完整，不保证延迟，不保证带宽等
	- 传输层可以通过差错恢复、重排序等手段提供可靠、按序的交付服务，但传输层无法提供延迟保证、带宽保证等服务
- 传输层服务
	- 将终端-终端的数据交付扩展到进程-进程的数据交付
	- 报文检错
	- 拓展服务
		- 可靠数据传输
		- 流量控制
		- 拥塞控制

# 2 套接字编程
---
- 进程标识
	- 主机地址
	- 主机与该进程关联的端口号
- 套接字描述符
- UDP 和 TCP 编程举例
	- TCP 有 listen 过程 分为 listen socket 和 临时的连接socket

# 3 传输层复用和分用
---
- 发送端复用 --- 传输层从多个套接字收集数据，交给网络层发送(多个端口套接字复用网络层)。发送方传输层将套接字标识置于报文段中，交给网络层
- 接收端分用 --- 传输层将从网络层收到的数据，交付给正确的套接字。接收方传输层根据报文段中的套接字标识，将报文段交付到正确的套接字

- 套接字端口号分配
	- 自动分配 --- 客户端
	- 使用指定端口号创建套接字(比如80等) --- 服务端

- UDP 分用
	- UDP套接字使用<IP地址, 端口号>二元组进行标识
	- <目的IP地址，目的端口号> 相同的UDP报文段被交付给同一个套接字，与 <源IP地址，源端口号> 无关（多对一）
	- 报文段中的 <源IP地址，源端口号> 被接收进程用来发送响应报文

- TCP 分用
	- 连接套接字需要使用<源IP地址，目的IP地址，源端口号，目的端口号>四元组进行标识，服务器使用该四元组将TCP报文段交付到正确的连接套接字
	- 一个TCP服务器为了同时服务很多个客户，使用两种套接字
		- 服务器平时在监听套接字上等待客户的连接请求，该套接字具有众所周知的端口号
		- 每个连接套接字只与一个客户通信，使用临时分配的端口号(只有四元组完全相同的才是同一个套接字即一对一)(💡目的端口号 = 服务器监听套接字的端口号)

# 4 无连接传输 UDP
---
- 校验和计算
	- 计算UDP校验和时，要包括伪头、UDP头和数据三个部分
	- UDP伪头信息取自IP报头，包括
		- 源IP地址，目的IP地址
		- UDP的协议号
		- UDP报文段总长度
	- UDP校验和的使用是可选的，若不计算校验和，该字段填入0
- UDP 既不保证顺序，也不保证不丢包，甚至可以不保证自己的数据报一定是对的（checksum可选）
- 若应用要求基于UDP进行可靠传输 --- 由应用层实现可靠性

# 5 面向连接传输 TCP
---
- 在一对通信的进程之间提供一条理想的字节流管道
	- 点到点通信 --- 仅涉及一对通信进程
	- 全双工
	- 可靠、有序的字节流 --- 不保留报文边界（一个segment的数据量可变）
		- 可靠传输：流水线式发送，报文段检错，丢失重传
		- 流量控制：发送方不会令接收方缓存溢出

- TCP 报文结构
	- TCP头长度，4字节为单位(比较偏的知识点)

- 发送序号与确认序号
	- 发送序号：数据载荷中第一个字节在字节流中的序号(每个字节或SYN或FIN都占一个seqno)

## 5.1 可靠数据传输
---
- 基本机制
	- 发送端：流水线式发送数据、等待确认、超时重传
	- 接收端：进行差错检测，采用累积确认机制
- 乱序段处理 --- 协议没有明确规定
	- 接收端不缓存：可以正常工作，处理简单，但效率低
	- 接收端缓存：效率高，但处理复杂 (我们采用的方式)(hold buffer 与 memory-resident)
- 定时器的使用：仅对最早未确认的报文段使用一个重传定时器（与GBN类似）--- 重发策略：仅在超时后重发最早未确认的报文段。只使用一个定时器，避免了超时设置过小时重发大量报文段

- 超时值设置 --- 超时值应当略大于RTT
	- 主要问题就是计算RTT，安全距离与平均RTT计算
	- SimpleRTT测量与EstimatedRTT计算：忽略二义性与定时器补偿
		- Karn 算法

- TCP接收端可以通过推迟确认和累计确认机制减少通信量
- TCP接收端的事件与处理![Pasted image 20241121115306.png](/img/user/MyCNnotes/assets/Pasted%20image%2020241121115306.png)
- TCP快速重传机制
	- 收到3次重复确认，重发报文段

- TCP与GBN和SR的比较

- Crash Recovery
	- 先写W后ACK or 先ACK后写W
	- S0 全部发送的包都确认了，S1有未确认的发送包

## 5.2 流量控制
---
- 发送端TCP通过调节发送速率，不使接收端缓存溢出
- 接收缓存中的可用空间称为接收窗口
	- RcvWindow = RcvBuffer-\[LastByteRcvd - LastByteRead\](rwnd)
- 发送方限制未确认的字节数不超过接收窗口的大小，即：
	- LastByteSent-LastByteAcked≦ RcvWindow
- 主要了解
	- 非零窗口通告与探测
		- 零窗口探测
		- 坚持定时器
	- 糊涂窗口综合症
		- 接收方和发送方启发式策略
		- 接收方当窗口大小显著增加时，才发送非零窗口通告(推迟发送仍是以500ms为极限，且至少每隔一个报文段使用正常方式进行确认) --- 什么是显著增加：窗口大小达到缓存空间的一半或者一个MSS，取两者的较小值
		- 发送方 Nagle算法，开始时是多少发多少，然后在ack没到时将数据累计在buffer中，当数据量达到一个MSS或ACK到达时打包为TCP段发送
	- ![Pasted image 20250103113050.png](/img/user/MyCNnotes/assets/Pasted%20image%2020250103113050.png)

# 5.3 连接管理
---
- 建立TCP连接
	- 双方均同意
	- 初始化参数
- 方法一：两次握手
	- 有各种问题比如 在回信息时，太慢，导致客户端发生重发，形成半开连接
	
	- 解决方法一：使用seqno，遇到之前有过的seqno，则丢弃。但是仍然有问题，因为序列号有限，seqno不能区别不同的包。
	
	- 解决方法二：1. Time for seqno wrap around (T1) is typically large(序列号多)；2. If pkt delays a relatively short time (T2<T1), we can use time to differentiate the two。基于这两个条件，那么我们遇到之前有过的seqno且时间短则丢掉，时间长的话还是接受。(相比方案一引入时间为了解决 delay duplicate
		- Restrict packet lifetime
		- use time-of-day clock to limit sending rate(起始的seqno是low k bits of time-of-day clock)
			- TCP 起始序号不能随便选取，发生序列号重叠而丢失
			- TCP 起始序号选择的方式
				- time of day clock 是本地时钟，每 4微妙增加 1
				- low k bits of time-of-day clock(k一般取32bits)
			- 仍然有可能的 Forbidden region(包不能发在Forbidden region之中，否则可能发生重叠问题)，限制发包速度，不能太快也不能太慢

- 方法二：三次握手
	- 它的seqno 也是通过取 low k bits of time-of-day clock
	- 可以解决之前二次握手的问题，不会有半开连接
	- SYN -> SYN,ACK -> ACK
	- TCP关闭连接
		- 异步，数据丢失可能
		- 同步，TCP使用，也可能出现问题，即 the two army problem
			- the two army problem 是说，我们两支部队要同时攻打另一支部队来协商攻打时间，我出一个通信兵然后通信兵回来了(二次握手)，这样我知道你知道3点打，但是你不知道我知道你知道3点打，因此陷入无限循环(一方必须明确对方已经知道3点打且明确对方知道自己知道对方3点打才行)(并没有很好的协议解决)
		- 四次挥手
			- FIN->ACK->FIN->ACK

- TCP 状态序列
- ![Pasted image 20250103151449.png](/img/user/MyCNnotes/assets/Pasted%20image%2020250103151449.png)

- SYN 洪泛攻击

- TCP端口扫描

# 6 网络拥塞
---
- 流量控制：限制发送速度，使不超过*接收端*的处理能力
- 拥塞控制：限制发送速度，使不超过*网络*的处理能力
- 拥塞控制方法
	- 网络辅助的拥塞控制 ---- 路由器向端系统提供显式的反馈，但是仍然存在问题，本来就堵显式回馈更堵
	- 端到端拥塞控制 --- 端系统通过观察丢包和延迟，自行推断拥塞的发生(TCP采用)

# 7 TCP 拥塞控制
---
- TCP使用端到端拥塞控制机制 --- 发送方根据自己感知的网络拥塞程度，限制其发送速率
	- 发送方利用丢包事件感知拥塞
		- 重传定时器超时
		- 发送端收到3个重复的ACK
	- 发送方使用拥塞窗口cwnd限制已发送未确认的数据量
	- 调节策略 --- AIMD
		- 乘性减（Multiplicative Decrease）--- 发送方检测到丢包后，将cwnd的大小减半（但不能小于一个MSS）
		- 加性增（Additive Increase） --- 若无丢包，每经过一个RTT，将cwnd增大一个MSS，直到检测到丢包
	- TCP 慢启动
		- 解决 加性增涨太慢，因此慢启动在新建连接上指数增大cwnd，直至检测到丢包（此时终止慢启动）
		- 慢启动实现
			- 每收到一个ACK段，cwnd增加一个MSS(ppt右侧的图展示了为什么这样就是指数增加)
		- 区分不同丢包事件
			- 收到3个重复的ACK（具备基本交付能力）
				- 将cwnd降至一半
				- 使用AIMD调节cwnd
			- 超时(非常严重，交付能力很差)
				- 设置门限 =cwnd/2
				- cwnd=1MSS
				- 使用慢启动增大cwnd至门限
				- 使用AIMD调节cwnd
		- 发送方维护 ssthresh(门限)
			- cwnd低于门限时，执行慢启动
			- cwnd高于门限：执行拥塞避免AIMD
			- 在AIMD时，每当收到ACK， cwnd=cwnd +MSS*(MSS/cwnd)(❓这个公式本质上就是实现了每次发送增大一个MSS，注意)
- TCP拥塞控制状态机
	- 基于的表格![Pasted image 20241128113753.png](/img/user/MyCNnotes/assets/Pasted%20image%2020241128113753.png)

- 对于无线连接，很容易丢包，可以采用重传来解决问题

- TCP 连接的吞吐量

- TCP的公平性
	- 采用AMID 是TCP是公平的，会不断逼近图中的点
	- 若相互竞争的TCP连接具有不同的参数（RTT、MSS等），不能保证公平性

# 8 拥塞控制的发展
----
- TCP-BIC
	- 窗口更新受ACK时钟驱动，即以RTT为更新间隔时间
	- BIC算法对满载窗口进行二分查找
		- 如发生丢包时窗口大小是W1，为保持满载而不丢包，满载窗口应小于W1
		- 如检测到丢包并将窗口乘性减小为W2 ，则满载窗口应大于W2
	- 二分查找 --- 在ACK时钟的驱动下，将拥塞窗口置为(W1 + W2)/2(新的W2值)
	- 最大探查 --- 如窗口再次达到W1而没有丢包，说明满载窗口大于W1 ，则以逼近W1的镜像过程增大拥塞窗口
	- BIC存在带宽不公平性问题 --- BIC以ACK时钟驱动拥塞窗口的更新，RTT较短的连接会更快到达满载窗口，占据更多的带宽，产生不公平性问题（RTT-fairness）

- TCP-CUBIC
	- 对BIC的改进
	- 拥塞窗口成为距上次丢包的时间t 的函数，t 取值位于两次丢包之间，不再根据RTT间隔来确定调整窗口的时机，避免了RTT不公平问题


- Google BBR
	- 拥塞与瓶颈链路
	-  在BDP时处理是最好了，但是并不能很好直接计算(两个折线图的转折点的纵坐标之积就是横坐标BDP，但是并不能很好地把握在此时正好测量到)
	- BDP检测
	- BBR状态机

- Data Center TCP
	- Incast
	- Queue Buildup
	- Buffer Pressure
	- DCTCP

# 9 传输层协议的发展
---
- 传统TCP协议仅支持单路径传输，即只能利用终端主机上的一个网络接口传输数据
	- 多路径TCP协议（MPTCP）应运而生，它可将单一数据流切分为若干子流，同时利用多条路径进行传输
- TCP 实现在操作系统内核中，作为传输优化的最终受益者，应用无法对TCP进行修改，操作系统的更新往往跟不上应用的需求和节奏；TCP体系握手时延大；TCP多流复用存在队头阻塞问题。
	- 基于QUIC的传输架构
		- QUIC替代TCP、TLS和部分HTTP的功能
		- QUIC实现在用户态中
		- 底层基于UDP实现